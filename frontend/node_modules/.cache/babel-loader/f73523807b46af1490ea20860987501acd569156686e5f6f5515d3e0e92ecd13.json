{"ast":null,"code":"import { createElementVNode as _createElementVNode, normalizeClass as _normalizeClass, openBlock as _openBlock, createElementBlock as _createElementBlock } from \"vue\";\nconst _hoisted_1 = {\n  class: \"audio-recorder\"\n};\nconst _hoisted_2 = [\"src\"];\nexport function render(_ctx, _cache, $props, $setup, $data, $options) {\n  return _openBlock(), _createElementBlock(\"div\", _hoisted_1, [_createElementVNode(\"button\", {\n    class: _normalizeClass([\"icon-button\", {\n      recording: $data.isRecording\n    }]),\n    onClick: _cache[0] || (_cache[0] = (...args) => $options.toggleRecording && $options.toggleRecording(...args))\n  }, [_createElementVNode(\"img\", {\n    src: require('@/assets/image/mic-icon.png'),\n    alt: \"录音\",\n    class: \"button-icon\"\n  }, null, 8 /* PROPS */, _hoisted_2)], 2 /* CLASS */)]);\n}","map":{"version":3,"names":["class","_createElementBlock","_hoisted_1","_createElementVNode","_normalizeClass","recording","$data","isRecording","onClick","_cache","args","$options","toggleRecording","src","require","alt","_hoisted_2"],"sources":["D:\\HCI_FINAL\\new_copy\\frontend\\src\\components\\AudioRecorder.vue"],"sourcesContent":["<template>\r\n  <div class=\"audio-recorder\">\r\n    <button \r\n      class=\"icon-button\" \r\n      :class=\"{ recording: isRecording }\"\r\n      @click=\"toggleRecording\"\r\n    >\r\n      <img \r\n        :src=\"require('@/assets/image/mic-icon.png')\" \r\n        alt=\"录音\" \r\n        class=\"button-icon\"\r\n      >\r\n    </button>\r\n  </div>\r\n</template>\r\n\r\n<script>\r\nexport default {\r\n  name: 'AudioRecorder',\r\n  emits: ['recognition-complete'],  // 显式声明组件发出的事件\r\n  data() {\r\n    return {\r\n      isRecording: false,\r\n      mediaRecorder: null,\r\n      audioChunks: [],\r\n      audioContext: null,\r\n    }\r\n  },\r\n  methods: {\r\n    async toggleRecording() {\r\n      if (this.isRecording) {\r\n        console.log('停止录音...');\r\n        this.stopRecording();\r\n      } else {\r\n        console.log('开始录音...');\r\n        await this.startRecording();\r\n      }\r\n    },\r\n\r\n    async startRecording() {\r\n      try {\r\n        const stream = await navigator.mediaDevices.getUserMedia({ \r\n          audio: {\r\n            channelCount: 1,\r\n            sampleRate: 16000,\r\n            sampleSize: 16,\r\n            echoCancellation: false,  // 关闭回声消除\r\n            noiseSuppression: false,  // 关闭噪声抑制\r\n            autoGainControl: false    // 关闭自动增益\r\n          } \r\n        });\r\n        \r\n        // 使用更兼容的格式\r\n        const mimeType = 'audio/webm';\r\n        this.mediaRecorder = new MediaRecorder(stream, {\r\n          mimeType: mimeType,\r\n          audioBitsPerSecond: 256000  // 提高比特率\r\n        });\r\n        \r\n        this.audioChunks = [];\r\n\r\n        this.mediaRecorder.ondataavailable = (event) => {\r\n          this.audioChunks.push(event.data);\r\n        };\r\n\r\n        this.mediaRecorder.onstop = async () => {\r\n          try {\r\n            const audioBlob = new Blob(this.audioChunks, { type: mimeType });\r\n            console.log('原始音频大小:', audioBlob.size);\r\n            \r\n            // 转换为WAV格式\r\n            const wavBlob = await this.convertToWav(audioBlob);\r\n            console.log('WAV音频大小:', wavBlob.size);\r\n            \r\n            await this.sendAudioToServer(wavBlob);\r\n          } catch (error) {\r\n            console.error('音频处理失败:', error);\r\n            this.$emit('recognition-complete', '音频处理失败，请重试');\r\n          }\r\n        };\r\n\r\n        // 设置更频繁的数据收集\r\n        this.mediaRecorder.start(100);  // 每100ms收集一次数据\r\n        this.isRecording = true;\r\n      } catch (error) {\r\n        console.error('录音失败:', error);\r\n        alert('无法访问麦克风，请确保已授予麦克风访问权限。');\r\n      }\r\n    },\r\n\r\n    // 将音频数据转换为WAV格式\r\n    async convertToWav(audioBlob) {\r\n      try {\r\n        const arrayBuffer = await audioBlob.arrayBuffer();\r\n        const audioContext = new (window.AudioContext || window.webkitAudioContext)({\r\n          sampleRate: 16000  // 确保采样率为16000Hz\r\n        });\r\n        \r\n        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);\r\n        console.log('音频信息:', {\r\n          sampleRate: audioBuffer.sampleRate,\r\n          numberOfChannels: audioBuffer.numberOfChannels,\r\n          duration: audioBuffer.duration\r\n        });\r\n        \r\n        // 创建WAV文件\r\n        const wavBuffer = this.audioBufferToWav(audioBuffer);\r\n        return new Blob([wavBuffer], { type: 'audio/wav' });\r\n      } catch (error) {\r\n        console.error('音频转换失败:', error);\r\n        throw error;\r\n      }\r\n    },\r\n\r\n    // 将AudioBuffer转换为WAV格式\r\n    audioBufferToWav(buffer) {\r\n      const numOfChan = buffer.numberOfChannels;\r\n      const length = buffer.length * numOfChan * 2;\r\n      const buffer2 = new ArrayBuffer(44 + length);\r\n      const view = new DataView(buffer2);\r\n      const channels = [];\r\n      let offset = 0;\r\n      let pos = 0;\r\n\r\n      // 写入WAV文件头\r\n      this.writeString(view, 0, 'RIFF');\r\n      view.setUint32(4, 36 + length, true);\r\n      this.writeString(view, 8, 'WAVE');\r\n      this.writeString(view, 12, 'fmt ');\r\n      view.setUint32(16, 16, true);\r\n      view.setUint16(20, 1, true);  // PCM格式\r\n      view.setUint16(22, numOfChan, true);\r\n      view.setUint32(24, 16000, true);  // 采样率固定为16000Hz\r\n      view.setUint32(28, 16000 * 2 * numOfChan, true);  // 字节率\r\n      view.setUint16(32, numOfChan * 2, true);  // 块对齐\r\n      view.setUint16(34, 16, true);  // 位深度\r\n      this.writeString(view, 36, 'data');\r\n      view.setUint32(40, length, true);\r\n\r\n      // 写入音频数据\r\n      for (let i = 0; i < buffer.numberOfChannels; i++) {\r\n        channels.push(buffer.getChannelData(i));\r\n      }\r\n\r\n      while (pos < buffer.length) {\r\n        for (let i = 0; i < numOfChan; i++) {\r\n          let sample = Math.max(-1, Math.min(1, channels[i][pos]));\r\n          sample = (0.5 + sample < 0 ? sample * 32768 : sample * 32767) | 0;\r\n          view.setInt16(44 + offset, sample, true);\r\n          offset += 2;\r\n        }\r\n        pos++;\r\n      }\r\n\r\n      return buffer2;\r\n    },\r\n\r\n    writeString(view, offset, string) {\r\n      for (let i = 0; i < string.length; i++) {\r\n        view.setUint8(offset + i, string.charCodeAt(i));\r\n      }\r\n    },\r\n\r\n    stopRecording() {\r\n      if (this.mediaRecorder && this.isRecording) {\r\n        this.mediaRecorder.stop();\r\n        this.isRecording = false;\r\n        this.mediaRecorder.stream.getTracks().forEach(track => track.stop());\r\n      }\r\n    },\r\n\r\n    async sendAudioToServer(audioBlob) {\r\n      try {\r\n        const formData = new FormData();\r\n        formData.append('audio', audioBlob, 'recording.wav');\r\n\r\n        console.log('正在发送音频到服务器...');\r\n        const response = await fetch('/api/audio/recognize', {\r\n          method: 'POST',\r\n          body: formData\r\n        });\r\n\r\n        const result = await response.json();\r\n        console.log('服务器返回结果:', result);\r\n        \r\n        if (!response.ok) {\r\n          throw new Error(result.error || '服务器错误');\r\n        }\r\n\r\n        if (result.success) {\r\n          // 发出识别完成事件，将识别结果发送给父组件\r\n          console.log('[AudioRecorder] 发送识别结果到父组件:', result.text);\r\n          \r\n          // 尝试多种方式触发事件\r\n          this.$emit('recognition-complete', result.text);\r\n          console.log('[AudioRecorder] 事件已发出');\r\n          \r\n          // 延迟100ms后再次发送事件，确保Vue更新周期捕获它\r\n          setTimeout(() => {\r\n            console.log('[AudioRecorder] 延迟发送事件');\r\n            this.$emit('recognition-complete', result.text);\r\n          }, 100);\r\n        } else {\r\n          console.error('语音识别失败:', result.error);\r\n          this.$emit('recognition-complete', '识别失败，请重试');\r\n        }\r\n      } catch (error) {\r\n        console.error('发送音频文件失败:', error);\r\n        this.$emit('recognition-complete', '识别失败，请重试');\r\n      }\r\n    },\r\n  },\r\n}\r\n</script>\r\n\r\n<style scoped>\r\n.audio-recorder {\r\n  display: inline-block;\r\n}\r\n\r\n.icon-button {\r\n  width: 40px;\r\n  height: 40px;\r\n  cursor: pointer;\r\n  background: none;\r\n  border: none;\r\n  padding: 8px;\r\n  transition: transform 0.2s;\r\n  display: flex;\r\n  align-items: center;\r\n  justify-content: center;\r\n  position: relative;\r\n  z-index: 1;\r\n}\r\n\r\n.button-icon {\r\n  width: 24px;\r\n  height: 24px;\r\n  object-fit: contain;\r\n}\r\n\r\n.icon-button:hover {\r\n  transform: scale(1.1);\r\n}\r\n\r\n.icon-button.recording {\r\n  animation: pulse 1.5s infinite;\r\n  filter: invert(48%) sepia(79%) saturate(2476%) hue-rotate(330deg) !important;\r\n}\r\n\r\n@keyframes pulse {\r\n  0% {\r\n    transform: scale(1);\r\n  }\r\n  50% {\r\n    transform: scale(1.05);\r\n  }\r\n  100% {\r\n    transform: scale(1);\r\n  }\r\n}\r\n</style> "],"mappings":";;EACOA,KAAK,EAAC;AAAgB;mBAD7B;;uBACEC,mBAAA,CAYM,OAZNC,UAYM,GAXJC,mBAAA,CAUS;IATPH,KAAK,EAHXI,eAAA,EAGY,aAAa;MAAAC,SAAA,EACEC,KAAA,CAAAC;IAAW;IAC/BC,OAAK,EAAAC,MAAA,QAAAA,MAAA,UAAAC,IAAA,KAAEC,QAAA,CAAAC,eAAA,IAAAD,QAAA,CAAAC,eAAA,IAAAF,IAAA,CAAe;MAEvBP,mBAAA,CAIC;IAHEU,GAAG,EAAEC,OAAO;IACbC,GAAG,EAAC,IAAI;IACRf,KAAK,EAAC;0BAVdgB,UAAA,E","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}